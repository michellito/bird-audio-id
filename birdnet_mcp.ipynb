{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c978b737-b8eb-4d19-a48a-e6051048b76f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Bird Species Identification with LLMs and BirdNET MCP üê¶\n",
    "\n",
    "### Overview ü¶Ü\n",
    "This notebook uses an MCP (Model Context Protocol) server to enable LLMs to interact with [BirdNET](https://birdnet.cornell.edu) for bird species identification.  BirdNET was developed by Cornell University's Lab of Ornithology and can identify over 6,000 bird species worldwide from their vocalizations.\n",
    "\n",
    "### Requirements ü¶â\n",
    "+ Python 3.11 or lower (required by `birdnet` package)\n",
    "+ To run on CyVerse: Use `Jupyter_Lab_PyTorch_CPU` VICE app. Tested with 8 CPU Cores, 64GB min memory, 128 min disk space\n",
    "+ MCP server implementation (`birdnet_mcp_server.py`)\n",
    "+ LLM API access (Provided through AI Verde: [https://chat.cyverse.ai](https://chat.cyverse.ai))\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae2a286-492c-4726-b81c-f63468cb5b9a",
   "metadata": {},
   "source": [
    "## Model Context Protocol (MCP)\n",
    "+ Open-source protocol by Anthropic (Nov 2024) to standardize how AI systems interact with external data sources and tools\n",
    "+ Allows LLMs to:\n",
    "    + Connect to data sources (databases, files, APIs)\n",
    "    + Call tools (functions the LLM can execute)\n",
    "    + Tools can make API calls, run software, search data, etc.\n",
    "+ Server/Client architecture:\n",
    "    + Server: Defines and exposes tools/resources\n",
    "    + Client: AI application that connects to servers\n",
    "    + LLM: Decides when to use which tools autonomously\n",
    "    + Python packages like `fastmcp` and `mcp_use` simplify building custom MCP servers and clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07520f6a-acfe-49b3-aad8-877a3c96aeee",
   "metadata": {},
   "source": [
    "![MCP Architecture](https://cdn.sanity.io/images/599r6htc/regionalized/da4205446e7c425053653d58c5aed6fac556c659-2160x1440.png?q=75&fit=max&auto=format&dpr=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93370f3f-a49d-4cf0-add0-48db4c648043",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Audio recordings are located in the `data` folder.  Use the following cell to listen to the recordings!\n",
    "\n",
    "File names for easy copy/paste if you'd like to test different audio files:\n",
    "\n",
    "+ XC358703-lesser-goldfinch.mp3\n",
    "+ XC436528-black-tailed-gnatcatcher.mp3\n",
    "+ XC528331-curve-billed-thrasher.mp3\n",
    "+ XC544598-verdin.mp3\n",
    "+ XC578664-rufous-winged-sparrow.mp3\n",
    "+ XC589950-gambels-quail.mp3\n",
    "+ XC66350-costas-hummingbird.mp3\n",
    "+ XC71035-broad-billed-hummingbird.mp3\n",
    "+ XC75502-annas-hummingbird.mp3\n",
    "+ XC767284-great-horned-owl.mp3\n",
    "+ XC872133-mourning-dove.mp3\n",
    "+ XC950378-aberts-towhee.wav\n",
    "+ XC982241-vermillion-flycatcher.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fab7358-4b32-4ea7-b79d-2dc7c3a02fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "# From a file\n",
    "Audio('./data/XC358703-lesser-goldfinch.mp3')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2adaf7-58d7-4c68-9e89-1d2e62acc5be",
   "metadata": {},
   "source": [
    "### Install required packages:\n",
    "- `langchain_openai` -  Wrapper for calling LLMs via OpenAI-compatible APIs\n",
    "- `birdnet` - Bird species identification model\n",
    "- `librosa`, `soundfile` - Audio processing libraries\n",
    "- `fastmcp` - MCP server framework\n",
    "- `mcp_use` - MCP client library that connects LLMs to MCP tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23232107-3105-4e91-bcc8-10fbeabd0a25",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q langchain_openai==0.3.34\n",
    "!pip install -q birdnet==0.1.7 librosa==0.11.0 soundfile==0.13.1\n",
    "!pip install -q fastmcp==2.12.4 mcp_use==1.3.11 asyncio==4.0.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabbdb1f-24c1-46a1-b9fb-67033ca24372",
   "metadata": {},
   "source": [
    "### Go to AI Verde\n",
    "#### Let's take a quick tour and grab our API Key while we're at it:\n",
    "[https://chat.cyverse.ai](https://chat.cyverse.ai)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9590cd2e-060c-4e71-91e2-67f4a4769b92",
   "metadata": {},
   "source": [
    "### Add your API Key\n",
    "\n",
    "When prompted below, enter your API Key from AI Verde:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36fc21f-f4f4-4038-9631-7a2047e964ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "api_key = getpass('Enter your API key & hit enter: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb25e021-7368-4287-b228-6c5aa149bc14",
   "metadata": {},
   "source": [
    "### Get listing of available models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02540fa5-d6e6-4f9c-a9de-898e52a8a433",
   "metadata": {},
   "source": [
    "The following `curl` command lists the available models for your API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47e5018-4c8c-4465-8941-4ffad55cca65",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -s -L \"https://llm-api.cyverse.ai/v1/models\" \\\n",
    "  -H \"Authorization: Bearer {api_key}\" \\\n",
    "  -H 'Content-Type: application/json' | json_pp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678256ba-25a8-4a44-95da-30d9df17881c",
   "metadata": {},
   "source": [
    "### Initialize LLM\n",
    "\n",
    "The following initializes the LLM from AI Verde  (in this case, `llama-4-scout` hosted by Jetstream 2, but feel free to try another model from the list!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef6d162-15ae-4f0e-8d61-007864a2398c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"js2/llama-4-scout\",\n",
    "    api_key=api_key,\n",
    "    base_url=\"https://llm-api.cyverse.ai/v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca098f7b-5642-4b9a-a32e-417ab5d87daf",
   "metadata": {},
   "source": [
    "Now we can test the LLM using `llm.invoke()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4188dd-292d-4a79-9f10-eb9673e1ef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (llm.invoke(\"Hello, world!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a936f3e-d152-4abb-a222-17a60b0edcae",
   "metadata": {},
   "source": [
    "### Run the MCP Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9753694-d5a0-43e5-985e-86cae0b041dd",
   "metadata": {},
   "source": [
    "We can run the MCP server directly from the notebook as a subprocess OR we can open a terminal and run it as its own process using `python birdnet_mcp_server.py` (from the same directory as the notebook).  The following cell runs it as a subprocess to keep everything in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98a8b26-e6e8-4ccd-8e01-3d5964470a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "# Start the server as a background process\n",
    "server_process = subprocess.Popen(\n",
    "    [\"python\", \"birdnet_mcp_server.py\"],\n",
    ")\n",
    "\n",
    "# Wait a moment for the server to start up\n",
    "time.sleep(5) \n",
    "print(\"MCP Server started in background on port 8000.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b56276e-d710-4b4b-9847-d9ea22eb2bf6",
   "metadata": {},
   "source": [
    "### Initialize the MCP client\n",
    "\n",
    "Connect to the BirdNET MCP server running on port 8000. The client enables the LLM to discover and call available tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91daab6c-54b9-4a70-bf17-5b4a82449d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcp_use import MCPClient\n",
    "\n",
    "client = MCPClient.from_dict({\n",
    "    \"mcpServers\": {\n",
    "        \"birdnet_server\": {\n",
    "            \"url\": \"http://127.0.0.1:8000/mcp\"\n",
    "            # \"command\": \"python\", \n",
    "            # \"args\": [\"./birdnet_mcp_server.py\"],\n",
    "            # \"transport\": \"stdio\" \n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a809f81-9f06-4cdc-8b78-80f490aaf40a",
   "metadata": {},
   "source": [
    "### Set up the agent and run with prompt\n",
    "\n",
    "The following function executes the MCP agent with a user prompt. The agent connects the LLM to MCP tools and orchestrates the workflow:\n",
    "1. **Agent** receives your prompt and gives the LLM access to BirdNET tools via MCP\n",
    "2. **LLM** reads the prompt, decides which BirdNET functions to call, and requests them\n",
    "3. **Agent** routes the tool calls through the MCP Client to the BirdNET MCP Server\n",
    "4. **BirdNET MCP Server** executes the analysis and returns results\n",
    "5. **Agent** feeds results back to the LLM, which interprets them into a natural language response\n",
    "\n",
    "**Parameters:**\n",
    "- `prompt`: Question or instruction about bird species identification\n",
    "- `max_steps`: Maximum tool calls the agent can make (default: 5)\n",
    "- `llm_instance`: Optional LLM to use, defaults to global `llm` if not specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e349e8c4-a2e7-45a1-a39b-f95fc96f3ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcp_use import MCPAgent\n",
    "\n",
    "async def run_agent_with_prompt(\n",
    "    prompt: str, \n",
    "    max_steps: int = 5,\n",
    "    llm_instance = None\n",
    "):\n",
    "    # Use provided LLM or fall back to global\n",
    "    active_llm = llm_instance if llm_instance is not None else llm\n",
    "    \n",
    "    agent = MCPAgent(llm=active_llm, client=client, max_steps=max_steps)\n",
    "    \n",
    "    print(f\"User Prompt: {prompt}\\n\")\n",
    "    print(\"--- Agent Execution ---\")\n",
    "    \n",
    "    result = await agent.run(prompt)\n",
    "    \n",
    "    print(\"\\n--- Final Answer ---\")\n",
    "    print(result)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bd800f-e0fb-4fb0-a888-eabd59037a74",
   "metadata": {},
   "source": [
    "### Experiment with different prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae1f5c2-d4b1-45fd-af19-c6df3f2e10e5",
   "metadata": {},
   "source": [
    "Add or modify prompts in the `TEST_PROMPTS` dictionary to experiment with different questions.\n",
    "\n",
    "**Usage:**\n",
    "- Run a test prompt: `await run_agent_with_prompt(TEST_PROMPTS[\"single_file\"])`\n",
    "- Run a custom prompt: `await run_agent_with_prompt(\"Your custom question here\")`\n",
    "\n",
    "File names for easy copy/paste if you'd like to test different audio files:\n",
    "\n",
    "+ XC358703-lesser-goldfinch.mp3\n",
    "+ XC436528-black-tailed-gnatcatcher.mp3\n",
    "+ XC528331-curve-billed-thrasher.mp3\n",
    "+ XC544598-verdin.mp3\n",
    "+ XC578664-rufous-winged-sparrow.mp3\n",
    "+ XC589950-gambels-quail.mp3\n",
    "+ XC66350-costas-hummingbird.mp3\n",
    "+ XC71035-broad-billed-hummingbird.mp3\n",
    "+ XC75502-annas-hummingbird.mp3\n",
    "+ XC767284-great-horned-owl.mp3\n",
    "+ XC872133-mourning-dove.mp3\n",
    "+ XC950378-aberts-towhee.wav\n",
    "+ XC982241-vermillion-flycatcher.wav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44456171-097c-4f46-80fc-57d63ff62217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prompts\n",
    "TEST_PROMPTS = {\n",
    "    \"single_file\": \"What bird species can be heard in ./data/XC589950-gambels-quail.mp3?\",\n",
    "    \"with_confidence\": \"Analyze ./data/XC589950-gambels-quail.mp3 and tell me which species you're most confident about.\",\n",
    "    \"multiple_analysis\": \"Compare bird species in ./data/XC589950-gambels-quail.mp3 and ./data/XC75502-annas-hummingbird.mp3\",\n",
    "    \"location_context\": \"What birds are typically found in Arizona based on the current date and location 32.2319¬∞ N, 110.9501¬∞ W?\",\n",
    "}\n",
    "\n",
    "# Usage examples (uncomment to use):\n",
    "\n",
    "# 1. Run a single prompt by key\n",
    "await run_agent_with_prompt(TEST_PROMPTS[\"single_file\"])\n",
    "\n",
    "# 2. Run a custom prompt\n",
    "# await run_agent_with_prompt(\"Compare bird species in ./data/XC589950-gambels-quail.mp3 and ./data/XC75502-annas-hummingbird.mp3\")\n",
    "\n",
    "# 3. Run a specific test prompt with confidence\n",
    "# result = await run_agent_with_prompt(TEST_PROMPTS[\"with_confidence\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6248a2b9-93da-4baf-9937-88ed6bbf4f0f",
   "metadata": {},
   "source": [
    "### Experiment with different LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0b21fc-a08a-442d-8d49-22e6a17eaf7a",
   "metadata": {},
   "source": [
    "Different LLMs have varying capabilities for tool use with MCP:\n",
    "- Some models may struggle to call tools correctly and consistently or call them unnecessarily\n",
    "- Others may fail to call tools at all even when needed\n",
    "\n",
    "**Performance depends on:**\n",
    "- The model's training for function calling & ability to interpret tool schemas  \n",
    "- **Tool schema quality** - clear descriptions, detailed parameter explanations, and examples in the `@mcp.tool()` decorator help the LLM understand when and how to use tools correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9514f2bc-8ad5-4865-b919-5bca22225aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate another LLM\n",
    "alt_llm = ChatOpenAI(\n",
    "    model=\"anvilgpt/gemma:latest\",\n",
    "    api_key=api_key,\n",
    "    base_url=\"https://llm-api.cyverse.ai/v1\"\n",
    ")\n",
    "\n",
    "# 3. Compare results from different LLMs\n",
    "llm_result = await run_agent_with_prompt(TEST_PROMPTS[\"single_file\"])\n",
    "alt_llm_result = await run_agent_with_prompt(TEST_PROMPTS[\"single_file\"], llm_instance=alt_llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91291837-de3c-43ce-ae0f-3468a87513d9",
   "metadata": {},
   "source": [
    "### Challenge Exercises ü¶Öüê¶\n",
    "\n",
    "1. Get LLM to successfully call `predict_species_by_location` MCP tool.  What model did you use? Did you have to modify the prompt or the tool itself?\n",
    "2. Add MCP tools to allow LLM to get the current date, and latitude and longitude for a city, so the user doesn't have to provide this information when predicting species by location/time of year.  Otherwise the LLM just makes stuff up for these values! üö®"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
